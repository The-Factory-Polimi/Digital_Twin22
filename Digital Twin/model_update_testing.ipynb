{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Update"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Update is the part of syncing the layout and stochastic distribution parameters of the system. Model update has two types.\n",
    "1. **Logic update** - Updating the layout and logic of the system (.json file of the digital model). It is done by regenerating the digital model using **model generation** techniques.\n",
    "2. **Input update** - Updating the stochastic parameters of the system such as stochastic processing time. The stochastic processing parameters are calculated per machine using the history of processing times **(Xr)** available in the real_log."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input update"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Modules"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Assumption\n",
    "We assume that processing time distribution is an inherent property of the machine, independent of its environment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Assumption:\n",
    "We assume that the dataset is made of only one distribution set. For cases of mixture of distributions, there are several types of mixture models, such as the Gaussian mixture model (GMM) and the finite mixture model (FMM), each with their own strengths and limitations. Mixture models can be a powerful tool for analyzing datasets with minimal data points and complex underlying distributions, but their application requires a solid understanding of statistical modeling and estimation techniques."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Available test methods\n",
    "1. Kolmogorov-Smirnov test (sensitive to differences in the tails of the distribution)\n",
    "2. Anderson-Darling test (sensitive to differences in the centre of the distribution)\n",
    "3. maximum likelihood estimation (for parameters estimation with a know distribution type)\n",
    "4. kernel density estimation (for PDF without knowing the distribution type)\n",
    "5. Shapiro-Wilk test for normal distribution (small dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datasets below 30 data points can be considered as a small sample size.\n",
    "Some academic sources that discuss sample size and statistical tests for determining the distribution of a dataset:\n",
    "\n",
    "1. Everitt, B. S. (2002). The Cambridge Dictionary of Statistics. Cambridge University Press.\n",
    "2. Wilcox, R. R. (2017). Introduction to robust estimation and hypothesis testing. Academic Press.\n",
    "3. Harwell, M. R., Stone, C. A., & Hsu, T. C. (1996). Sample size planning for statistical power and accuracy in parameter estimation. Boca Raton: CRC Press.\n",
    "4. McDonald, J. H. (2014). Handbook of Biological Statistics. Sparky House Publishing.\n",
    "5. NIST/SEMATECH e-Handbook of Statistical Methods, http://www.itl.nist.gov/div898/handbook/, accessed on January 11, 2023.\n",
    "\n",
    "It is important to note that these sources provide general guidelines and that the appropriate sample size and statistical test should be chosen based on the specific research question and context."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The assumptions and limitations of the Kolmogorov-Smirnov (KS) test and Anderson-Darling (AD) test are:\n",
    "\n",
    "1. The KS test assumes that the distribution being tested is continuous, while the AD test can be used for both continuous and discrete distributions.\n",
    "2. The AD test is known to be more powerful than the KS test for identifying deviations from the hypothesized distribution in the tails of the distribution, but the KS test is more sensitive to differences in the center of the distribution.\n",
    "3. Both tests assume that the sample data is independent and identically distributed.\n",
    "4. Both tests assume that the sample data is a random sample from the population being tested.\n",
    "\n",
    "The choice of which test to use depends on the specific context of the analysis and the distribution being tested. In general, it is recommended to use both tests and compare their results to gain a better understanding of the distribution being tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
